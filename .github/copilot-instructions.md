# Copilot Instructions — Node.js Chat Bot Backend

## General Principles
- Generate production-ready code.
- Use Node.js LTS APIs only.
- Prefer TypeScript over JavaScript.
- Use async/await; avoid callbacks.
- Avoid unnecessary dependencies.
- Prefer pure functions and small modules.

## Architecture Rules
The project follows layered architecture:

- routes/        → HTTP or webhook endpoints
- controllers/   → request handling
- services/      → business logic and AI orchestration
- providers/     → LLM / external API integrations
- repositories/  → database operations
- middleware/    → validation, auth, logging
- types/         → shared types
- utils/         → helper functions
- config/        → environment configuration

Copilot MUST NOT:
- put business logic into routes
- call LLM providers directly from controllers
- access database outside repositories

## Chat Bot Logic
- Separate conversation state management from message processing.
- Keep prompt-building logic in dedicated modules.
- Use service layer for:
  - conversation flow
  - context aggregation
  - memory handling
  - tool execution
- Support stateless request processing when possible.

## Conversation State
- Store conversation history via repository layer.
- Never store full raw prompts if they contain secrets.
- Limit stored message length.
- Include timestamps and role metadata.

Example message model:

{
  id: string
  role: 'system' | 'user' | 'assistant' | 'tool'
  content: string
  createdAt: Date
}

## LLM Integration Rules
- All AI calls go through providers/.
- Do not expose API keys in code.
- Load secrets from process.env.
- Support:
  - retries
  - timeout
  - rate limit handling
- Always validate AI responses.

## Prompt Engineering Rules
- Prompts must be generated by dedicated functions.
- Avoid inline prompts in controllers.
- Support system + user + memory messages.
- Keep prompts deterministic where possible.
- Avoid dynamic string concatenation without sanitization.

## Streaming Responses
- Support streaming tokens when provider allows.
- Use async generators or streams.
- Do not buffer large responses in memory.

## Validation
- Validate all incoming messages.
- Use schema validation (zod recommended).
- Validate:
  - message text
  - user id
  - conversation id
  - attachments metadata

Reject invalid input early.

## Security Rules
- Never log:
  - tokens
  - API keys
  - private messages marked confidential
- Treat all input as untrusted.
- Sanitize text before prompt injection into LLM.
- Implement prompt injection mitigation layer.

## Prompt Injection Protection
Copilot must generate:
- system prompt isolation
- tool call validation
- input filtering
- allowed tools whitelist

Never execute model-generated code automatically.

## Tools / Function Calling
- Tool execution must be isolated.
- Validate tool parameters with schemas.
- Timeout long-running tools.
- Log tool execution safely.

## Error Handling
- Use centralized error middleware.
- Throw typed errors.
- Never expose stack traces to users.
- Provide user-safe error messages.

## Logging
- Structured logs only.
- Include:
  - request id
  - conversation id
  - latency
- Avoid logging full prompts.

## Performance
- Avoid blocking operations.
- Cache system prompts.
- Reuse HTTP clients.
- Use queue for long AI tasks.

## Testing
- Unit test services and prompt builders.
- Mock LLM providers.
- Do not call real AI APIs in tests.

## Response Format
All API responses must follow:

{
  "success": boolean,
  "data": any,
  "error": string | null
}

## TypeScript Rules
- Avoid `any`.
- Use explicit return types.
- Prefer discriminated unions for message roles.
- Use readonly for immutable objects.
- Use strict null checks assumptions.
